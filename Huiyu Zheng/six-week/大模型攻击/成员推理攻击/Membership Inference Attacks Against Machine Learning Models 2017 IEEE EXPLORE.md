## Membership Inference Attacks Against Machine Learning Models 2017 IEEE EXPLORE

给定**数据记录**和对**模型的黑盒访问**，确定该记录是否在模型的训练数据集中。

> ? 这个数据记录是什么意思

背景：互联网巨头提供机器学习服务

作者贡献：给定一个机器学习模型和一条记录，确定此记录是否被用作是否是模型训练数据集的一部分。我们在最困难的环境中研究了这个问题，其中**对手对模型的访问仅限于黑盒查询**，这些查询**返回给定输入的模型输出**。总之，我们通过**机器学习模型的预测输出**来量化成员信息泄漏。

做法大概：训练一个攻击模型，将这个问题转化为一个二分类的问题。

环境：未知模型，未知数据。

**具体做法**：

1、创建多个“影子模型”。这些模型模仿目标模型行为。

2、在影子模型的标记输入和输出上训练攻击模型。

> 标记输入和输出是什么？

影子模型生成训练数据方法

- 对目标模型的黑盒访问合成数据（纯黑盒）
- 使用有关从中提取目标训练数据集的总体的统计数据
- 假设攻击者可以访问目标训练数据的干扰版本。

**结果**：证明了成员推理攻击可行，并且量化了成功分类任务和过拟合标准指标的关系。